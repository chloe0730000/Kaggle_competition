{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "- change learning rate to 0.07 from 0.05 -> score increase from 5560 to 5590 \n",
    "- not removing outlier currently since the output becomes worse\n",
    "- add interaction terms and change parameters -> 5590 to 5593\n",
    "    - add square, cubic and quadratic for interaction terms -> 5593 -> 5663\n",
    "    - change interaction terms (add few more compared with old one) and add two more features -> 5713\n",
    "        - add good factor -> 5713 -> 5717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from scipy.stats import norm, stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/chloe/Documents/GitHub/Kaggle_competition/TBrain/Yushan/Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Handle Missing value</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na = (df.isnull().sum() / len(df)) * 100\n",
    "train_na = train_na.drop(train_na[train_na == 0].index).sort_values(ascending=False)[:30]\n",
    "\n",
    "print(\"Missing value percentage by column: \\n\")\n",
    "print(train_na)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.xticks(rotation='-40')\n",
    "sns.barplot(x=train_na.index, y=train_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Remove \"parking_area\" due to over 94% missing value percentage</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['parking_area'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fill NA value by features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null parking_price all with parking_way=2 -> can directly replace the null with zero\n",
    "df['parking_price'] = df['parking_price'].fillna(0)\n",
    "df['village_income_median'] = df['village_income_median'].fillna(df['village_income_median'].mean())\n",
    "df['txn_floor'] = df['txn_floor'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Observe total_price distribution</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['total_price'] , fit=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>total_price's distribution is screwed right and has outlier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle screwed right\n",
    "df[\"total_price\"] = np.log1p(df[\"total_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['total_price'] , fit=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle outlier (removing outlier make it worse)\n",
    "q = df[\"total_price\"].quantile(0.99)\n",
    "\n",
    "test = df[df[\"total_price\"] < q]\n",
    "#df = df[df[\"total_price\"] < q]\n",
    "\n",
    "print(\"# of data exclude outlier:\", 60000-test.shape[0])\n",
    "sns.distplot(test[\"total_price\"], fit=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_col = [\"city\", \"town\", \"village\"]\n",
    "main_col = [\"village_income_median\", \"town_population\", \"town_area\",\n",
    "            \"city\", \"town\", \"village\",\"land_area\", \"building_area\"] \n",
    "interact_col = [col for col in df.columns if re.search(\"[a-zA-Z]_rate$\", col, re.IGNORECASE)!=None]\n",
    "#interact_col = interact_col+[\"death_date\"] # meaning death_rate -> better not include the death_rate\n",
    "\n",
    "for m_col in main_col:\n",
    "    for i_col in interact_col:\n",
    "        df[m_col+\"_\"+i_col+\"_IT\"] = df[m_col]*df[i_col]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_col = [col for col in df.columns if re.search(\"_IT$\", col, re.IGNORECASE)!=None]\n",
    "#list_to_square = interact_col+[\"village_income_median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in interact_col:\n",
    "    df[col+\"_s\"] = df[col]**2\n",
    "    #df[col+\"_c\"] = df[col]**3\n",
    "    #df[col+\"_q\"] = df[col]**4\n",
    "\n",
    "# for col in list_to_square:\n",
    "#     df[col+\"_s\"] = df[col]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ratio_floor\"] = df[\"txn_floor\"]/df[\"total_floor\"]\n",
    "df[\"ratio_parking_price\"] = df[\"parking_price\"]/df[\"village_income_median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"good_factor\"] = df[\"marriage_rate\"]+df[\"master_rate\"]+df[\"bachelor_rate\"]\n",
    "df[\"good_factor\"+\"_s\"] = df[\"good_factor\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_land_ratio(row):\n",
    "#     if row[\"land_area\"]>row[\"building_area\"]:\n",
    "#         return row[\"land_area\"]/row[\"building_area\"]\n",
    "#     elif row[\"land_area\"]==0:\n",
    "#         return row[\"land_area\"]/row[\"building_area\"]\n",
    "#     else:\n",
    "#         return row[\"land_area\"]/row[\"building_area\"]   \n",
    "        \n",
    "# df[\"land_ratio\"] = df.apply(get_land_ratio, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create training and testing set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove useless feature\n",
    "df = df.drop(['building_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splite to X, y dataframe\n",
    "df_price = df['total_price']\n",
    "df = df.drop(['total_price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 5 # set seed for same train test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df_price, random_state=random_seed, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Use random search to find best parameters for lightGBM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper_space = {'n_estimators': sp_randint(1000, 7000),\n",
    "#                'max_depth':  [15, 16, 17, 18, 19, 20 ,-1],\n",
    "#                'num_leaves': [20,30,40, 50, 60, 70, 80],\n",
    "#                'subsample': sp_uniform(0.6, 0.4),\n",
    "#                'colsample_bytree': sp_uniform(0.6, 0.4),\n",
    "#                 'learning_rate': [0.03, 0.05, 0.07, 0.1]}\n",
    "\n",
    "# gbm = lgb.LGBMRegressor(objective='regression',num_leaves=250,learning_rate=0.05,n_estimators=1500)\n",
    "\n",
    "# rs = RandomizedSearchCV(gbm, hyper_space, n_iter=60, scoring='r2', cv=4, \n",
    "#                          verbose=1, random_state=2018)\n",
    "# rs_results = rs.fit(X_train, y_train)\n",
    "# print(\"BEST PARAMETERS: \" + str(rs_results.best_params_))\n",
    "# print(\"BEST CV SCORE: \" + str(rs_results.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters with additional features\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=80,\n",
    "                        #learning_rate=0.01,\n",
    "                        learning_rate=0.03,\n",
    "                        n_estimators=6769,\n",
    "                       colsample_bytree = 0.6886781648348815,\n",
    "                       max_depth = 18,\n",
    "                       subsample = 0.7241144257909466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate model by hit rate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: 0.54; using exclude outlier: 0.55 but public score low\n",
    "# changing learning rate to 0.01 -> 0.495; 0.1 -> 0.538; 0.07 -> 0.548; 0.09 -> 0.5386; 0.08 -> 0.5378\n",
    "\n",
    "# (exclude outlier) -> 0.07 -> 0.5396; 0.05 -> 0.540; 0.1 -> 0.538; 0.03 -> 0.529\n",
    "# with additional features -> 0.03 -> 0.5527; 0.05 -> 0.551; 0.01 -> 0.534\n",
    "p = np.abs(( np.exp(y_pred) - np.exp(y_test) )/ np.exp(y_test))\n",
    "np.sum((p <=.1))/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predict test value for submission</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/chloe/Documents/GitHub/Kaggle_competition/TBrain/Yushan/Dataset/test.csv')\n",
    "test_df = test_df.drop(['building_id','parking_area'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fit the shape of training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['parking_price'] = test_df['parking_price'].fillna(0)\n",
    "test_df['village_income_median'] = test_df['village_income_median'].fillna(test_df['village_income_median'].mean())\n",
    "test_df['txn_floor'] = test_df['txn_floor'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m_col in main_col:\n",
    "    for i_col in interact_col:\n",
    "        test_df[m_col+\"_\"+i_col+\"_IT\"] = test_df[m_col]*test_df[i_col]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in interact_col:\n",
    "    test_df[col+\"_s\"] = test_df[col]**2\n",
    "    #test_df[col+\"_c\"] = test_df[col]**3\n",
    "    #test_df[col+\"_q\"] = test_df[col]**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"ratio_floor\"] = test_df[\"txn_floor\"]/test_df[\"total_floor\"]\n",
    "test_df[\"ratio_parking_price\"] = test_df[\"parking_price\"]/test_df[\"village_income_median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"good_factor\"] = test_df[\"marriage_rate\"]+test_df[\"master_rate\"]+test_df[\"bachelor_rate\"]\n",
    "test_df[\"good_factor\"+\"_s\"] = test_df[\"good_factor\"]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predict...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict value\n",
    "y_sub_GBM = gbm.predict(test_df)\n",
    "\n",
    "# Get inverse of log value\n",
    "y_sub_GBM = np.exp(y_sub_GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('/Users/chloe/Documents/GitHub/Kaggle_competition/TBrain/Yushan/Dataset/test.csv')\n",
    "output = output[[\"building_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"total_price\"] = y_sub_GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"/Users/chloe/Desktop/submission_learning_rate_20190623.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
